{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NARM+\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing functions.\n",
    "import pandas\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "from collections import namedtuple\n",
    "import itertools\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas\n",
    "import random\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USERID</th>\n",
       "      <th>PRODUCTID</th>\n",
       "      <th>CATEGORYID</th>\n",
       "      <th>ACTION</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>SESSION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2268318</td>\n",
       "      <td>2520377</td>\n",
       "      <td>pv</td>\n",
       "      <td>1511544070</td>\n",
       "      <td>2017-11-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2333346</td>\n",
       "      <td>2520771</td>\n",
       "      <td>pv</td>\n",
       "      <td>1511561733</td>\n",
       "      <td>2017-11-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2576651</td>\n",
       "      <td>149192</td>\n",
       "      <td>pv</td>\n",
       "      <td>1511572885</td>\n",
       "      <td>2017-11-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3830808</td>\n",
       "      <td>4181361</td>\n",
       "      <td>pv</td>\n",
       "      <td>1511593493</td>\n",
       "      <td>2017-11-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4365585</td>\n",
       "      <td>2520377</td>\n",
       "      <td>pv</td>\n",
       "      <td>1511596146</td>\n",
       "      <td>2017-11-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   USERID  PRODUCTID  CATEGORYID ACTION   TIMESTAMP     SESSION\n",
       "0       1    2268318     2520377     pv  1511544070  2017-11-24\n",
       "1       1    2333346     2520771     pv  1511561733  2017-11-24\n",
       "2       1    2576651      149192     pv  1511572885  2017-11-25\n",
       "3       1    3830808     4181361     pv  1511593493  2017-11-25\n",
       "4       1    4365585     2520377     pv  1511596146  2017-11-25"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create sessions\n",
    "sample = pandas.read_pickle(\"./data/smallTaoBao.pkl\")\n",
    "sample['SESSION'] = pandas.to_datetime(unpickled_smallTaoBao['TIMESTAMP'],unit='s').dt.date\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of sessions per user\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.2"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Average number of sessions per user\")\n",
    "unpickled_smallTaoBao.groupby('USERID')['SESSION'].nunique().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of clicks per session\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14.126388888888888"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Average number of clicks per session\")\n",
    "sample.groupby(['USERID', 'SESSION'])['ACTION'].count().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USERID</th>\n",
       "      <th>PRODUCTID</th>\n",
       "      <th>CATEGORYID</th>\n",
       "      <th>ACTION</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>SESSION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2268318</td>\n",
       "      <td>2520377</td>\n",
       "      <td>pv</td>\n",
       "      <td>1511544070</td>\n",
       "      <td>2017-11-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2333346</td>\n",
       "      <td>2520771</td>\n",
       "      <td>pv</td>\n",
       "      <td>1511561733</td>\n",
       "      <td>2017-11-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2576651</td>\n",
       "      <td>149192</td>\n",
       "      <td>pv</td>\n",
       "      <td>1511572885</td>\n",
       "      <td>2017-11-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3830808</td>\n",
       "      <td>4181361</td>\n",
       "      <td>pv</td>\n",
       "      <td>1511593493</td>\n",
       "      <td>2017-11-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4365585</td>\n",
       "      <td>2520377</td>\n",
       "      <td>pv</td>\n",
       "      <td>1511596146</td>\n",
       "      <td>2017-11-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   USERID  PRODUCTID  CATEGORYID ACTION   TIMESTAMP     SESSION\n",
       "0       1    2268318     2520377     pv  1511544070  2017-11-24\n",
       "1       1    2333346     2520771     pv  1511561733  2017-11-24\n",
       "2       1    2576651      149192     pv  1511572885  2017-11-25\n",
       "3       1    3830808     4181361     pv  1511593493  2017-11-25\n",
       "4       1    4365585     2520377     pv  1511596146  2017-11-25"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user1 = sample.loc[unpickled_smallTaoBao['USERID'] == 1]\n",
    "user1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2268318, 2333346], [2576651, 3830808, 4365585, 4606018, 230380], [3827899, 3745169, 1531036], [2266567, 2951368, 3108797, 1338525, 2286574], [5002615, 2734026, 5002615, 3239041, 4615417, 4152983, 266784, 46259, 266784, 4092065, 1305059], [2791761, 3239041, 46259, 4973305, 2087357, 3157558], [2087357, 4170517, 1340922, 3911125, 4170517, 3682069, 4954999, 79715, 4666650], [1323189, 4198227, 4954999], [2041056, 3219016, 2104483, 2028434, 3219016, 2278603, 929177], [4954999, 818610, 271696, 568695]]\n"
     ]
    }
   ],
   "source": [
    "# Create nested list of sessions and items per user\n",
    "userBase = sample.groupby(['USERID', 'SESSION'])['PRODUCTID'].apply(list).groupby('USERID').apply(list)\n",
    "print(userBase[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example(userID=1, history=[[2268318, 2333346], [2576651, 3830808, 4365585, 4606018, 230380], [3827899, 3745169, 1531036], [2266567, 2951368, 3108797, 1338525, 2286574], [5002615, 2734026, 5002615, 3239041, 4615417, 4152983, 266784, 46259, 266784, 4092065, 1305059], [2791761, 3239041, 46259, 4973305, 2087357, 3157558], [2087357, 4170517, 1340922, 3911125, 4170517, 3682069, 4954999, 79715, 4666650], [1323189, 4198227, 4954999]], inputs=[2041056, 3219016, 2104483, 2028434, 3219016, 2278603, 929177], target=[3219016, 2104483, 2028434, 3219016, 2278603, 929177])\n",
      "\n",
      "Example(userID=1, history=[[2268318, 2333346], [2576651, 3830808, 4365585, 4606018, 230380], [3827899, 3745169, 1531036], [2266567, 2951368, 3108797, 1338525, 2286574], [5002615, 2734026, 5002615, 3239041, 4615417, 4152983, 266784, 46259, 266784, 4092065, 1305059], [2791761, 3239041, 46259, 4973305, 2087357, 3157558], [2087357, 4170517, 1340922, 3911125, 4170517, 3682069, 4954999, 79715, 4666650], [1323189, 4198227, 4954999], [2041056, 3219016, 2104483, 2028434, 3219016, 2278603, 929177]], inputs=[4954999, 818610, 271696, 568695], target=[818610, 271696, 568695])\n"
     ]
    }
   ],
   "source": [
    "# More efficient create examples function\n",
    "# A simple way to define a class is using namedtuple.\n",
    "Example = namedtuple(\"Example\", [\"userID\", \"history\", \"inputs\", \"target\"])\n",
    "\n",
    "def f(userid, sessions, train):\n",
    "    if train:\n",
    "        object_train = Example(userID = userid, history = sessions[:-2], inputs = sessions[-2], target = sessions[-2][1:])\n",
    "        return object_train\n",
    "    else:\n",
    "        return Example(userID = userid, history = sessions[:-1], inputs = sessions[-1], target = sessions[-1][1:])\n",
    "\n",
    "def createExamples(userBase):\n",
    "    ''' Create training and testing set '''\n",
    "    userBase = pandas.DataFrame(userBase)\n",
    "    userBase.reset_index(level = 0, inplace = True)\n",
    "    trainData = userBase.apply(lambda x: f(x['USERID'], x['PRODUCTID'], True), axis = 1).tolist()\n",
    "    testData = userBase.apply(lambda x: f(x['USERID'], x['PRODUCTID'], False), axis = 1).tolist()\n",
    "    return trainData, testData\n",
    "\n",
    "trainData, testData = createExamples(userBase)\n",
    "print(trainData[0])\n",
    "print('')\n",
    "print(testData[0])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will probably take very long for entire dataset, code above does the same\n",
    "# IDs = list(sample.USERID.unique())\n",
    "# sessions = sorted(list(unpickled_smallTaoBao.SESSION.unique()))\n",
    "# userBase = defaultdict(list)\n",
    "\n",
    "# for ID in IDs:\n",
    "#     userData = sample.loc[unpickled_smallTaoBao['USERID'] == ID]\n",
    "    \n",
    "#     #Verschil tussen historical data and current session.\n",
    "    \n",
    "#     for session in sessions:\n",
    "#         userSession = userData.loc[userData['SESSION'] == session]\n",
    "#         userData_PRODUCTLIST = userSession['PRODUCTID'].values.tolist()\n",
    "        \n",
    "#         if len(userData_PRODUCTLIST) > 0:\n",
    "#             userBase[ID].append(userData_PRODUCTLIST)\n",
    "    \n",
    "    \n",
    "\n",
    "# print(userBase[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example(userID=1, history=[[2268318, 2333346], [2576651, 3830808, 4365585, 4606018, 230380], [3827899, 3745169, 1531036], [2266567, 2951368, 3108797, 1338525, 2286574], [5002615, 2734026, 5002615, 3239041, 4615417, 4152983, 266784, 46259, 266784, 4092065, 1305059], [2791761, 3239041, 46259, 4973305, 2087357, 3157558], [2087357, 4170517, 1340922, 3911125, 4170517, 3682069, 4954999, 79715, 4666650], [1323189, 4198227, 4954999]], inputs=[2041056, 3219016, 2104483, 2028434, 3219016, 2278603], target=[3219016, 2104483, 2028434, 3219016, 2278603, 929177])\n",
      "Example(userID=1, history=[[2268318, 2333346], [2576651, 3830808, 4365585, 4606018, 230380], [3827899, 3745169, 1531036], [2266567, 2951368, 3108797, 1338525, 2286574], [5002615, 2734026, 5002615, 3239041, 4615417, 4152983, 266784, 46259, 266784, 4092065, 1305059], [2791761, 3239041, 46259, 4973305, 2087357, 3157558], [2087357, 4170517, 1340922, 3911125, 4170517, 3682069, 4954999, 79715, 4666650], [1323189, 4198227, 4954999], [2041056, 3219016, 2104483, 2028434, 3219016, 2278603, 929177]], inputs=[4954999, 818610, 271696], target=[818610, 271696, 568695])\n"
     ]
    }
   ],
   "source": [
    "# # DON'T RUN THIS YET, NEEDS REWORKING\n",
    "\n",
    "# # Create dataset of examples\n",
    "\n",
    "# # A simple way to define a class is using namedtuple.\n",
    "# Example = namedtuple(\"Example\", [\"userID\", \"history\", \"inputs\", \"target\"])\n",
    "\n",
    "# def createExamples(userBase, IDs):\n",
    "#     # convert raw data into examples and create dataset\n",
    "    \n",
    "#     #TODO: create train and testdata\n",
    "#     #Example = userID, history, inputs, targets\n",
    "    \n",
    "#     trainData = []\n",
    "#     testData = []\n",
    "    \n",
    "    \n",
    "    \n",
    "#     for ID in IDs:\n",
    "#         userData = userBase[ID]\n",
    "#         historyTrain = userData[:-2]\n",
    "#         inputsTrain = userData[len(userData) -2]\n",
    "#         trainData.append(Example(userID = ID, history = historyTrain, inputs=inputsTrain[:-1],target=inputsTrain[1:]))\n",
    "        \n",
    "#         historyTest = userData[:-1]\n",
    "#         inputsTest = userData[len(userData) - 1]\n",
    "#         testData.append(Example(userID = ID, history = historyTest, inputs=inputsTest[:-1], target=inputsTest[1:]))\n",
    "        \n",
    "#     return trainData, testData\n",
    "\n",
    "# trainData, testData = createExamples(userBase, IDs)\n",
    "# print(trainData[0])\n",
    "# print(testData[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS\n",
    "\n",
    "# function to yield one example at a time\n",
    "def get_examples(data, shuffle=True, **kwargs):\n",
    "    \"\"\"Shuffle data set and return 1 example at a time (until nothing left)\"\"\"\n",
    "    if shuffle:\n",
    "#         print(\"Shuffling training data\")\n",
    "        random.shuffle(data)  # shuffle training data each epoch\n",
    "    for example in data:\n",
    "        yield example\n",
    "    \n",
    "# function to prepare an example for usage by the model\n",
    "def prepare_example(example):\n",
    "    \"\"\"\n",
    "    Turn an example into tensors of inputs and target.\n",
    "    \"\"\"\n",
    "    v = torch.FloatTensor([example.userID])\n",
    "    v = v.to(device)\n",
    "    \n",
    "    w = torch.FloatTensor([example.history])\n",
    "    w = w.to(device)\n",
    "    \n",
    "    x = torch.FloatTensor([example.inputs])\n",
    "    x = x.to(device)\n",
    "\n",
    "    y = torch.FloatTensor([example.target])\n",
    "    y = y.to(device)\n",
    "\n",
    "    return v, w, x, y\n",
    "\n",
    "# function to yield a (mini-)batch\n",
    "def get_minibatch(data, batch_size=25, shuffle=True):\n",
    "    \"\"\"Return minibatches, optional shuffling\"\"\" \n",
    "    if shuffle:\n",
    "#         print(\"Shuffling training data\")\n",
    "        random.shuffle(data)  # shuffle training data each epoch\n",
    "\n",
    "    batch = []\n",
    "\n",
    "    # yield minibatches\n",
    "    for example in data:\n",
    "        batch.append(example)\n",
    "\n",
    "        if len(batch) == batch_size:\n",
    "            yield batch\n",
    "            batch = []    \n",
    "        # in case there is something left\n",
    "        if len(batch) > 0:\n",
    "            yield batch\n",
    "\n",
    "# function to make the (mini-)batch ready for usage by the model\n",
    "def prepare_minibatch(mb):\n",
    "    \"\"\"\n",
    "    Minibatch is a list of examples.\n",
    "    This function converts returns\n",
    "    torch tensors to be used as input/targets.\n",
    "    \"\"\"\n",
    "    batch_size = len(mb)\n",
    "    x = [ex.inputs for ex in mb]\n",
    "    x = torch.FloatTensor(x)\n",
    "    x = x.to(device)\n",
    "\n",
    "    y = [ex.target for ex in mb]\n",
    "    y = torch.FloatTensor(y)\n",
    "    y = y.to(device)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "# simple evaluation function\n",
    "def simple_evaluate(model, data, prep_fn=prepare_example, **kwargs):\n",
    "    \"\"\"Explained Variance Score of a model on given data set.\"\"\"\n",
    "    model.eval()  # disable dropout (explained later)\n",
    "    targets = []\n",
    "    predictions = []\n",
    "\n",
    "    for example in data:\n",
    "\n",
    "        # convert the example input and label to PyTorch tensors\n",
    "        targets.append(example.target)\n",
    "        x, target = prepare_example(example)\n",
    "\n",
    "        # forward pass\n",
    "        # get the output from the neural network for input x\n",
    "        with torch.no_grad():\n",
    "            output = model(x)\n",
    "        # output shape: (batch, output_size)\n",
    "        prediction = output[0].tolist()\n",
    "        predictions.append(prediction)\n",
    "            \n",
    "    score = explained_variance_score(targets, predictions, multioutput='variance_weighted')\n",
    "\n",
    "    return score, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "non-default argument follows default argument (<ipython-input-124-07df95cea523>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-124-07df95cea523>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    def __init__(self, input_dim, embedding_dim, hidden_size, output_dim, num_layers, activation_fn=nn.RReLU(),num_items):\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m non-default argument follows default argument\n"
     ]
    }
   ],
   "source": [
    "# Custom NN\n",
    "\n",
    "class NarmPlus(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_size, output_dim, num_layers, activation_fn=nn.RReLU(),num_items):\n",
    "        super(NarmPlus, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_state_dim = (num_layers, 1, hidden_size)\n",
    "        self.hidden_state_size = num_layers * hidden_size\n",
    "        self.UserEmbedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.ItemEmbedding = nn.Embedding(num_items, embedding_dim)\n",
    "        self.ActivationFn = activation_fn\n",
    "        self.UserHistory = nn.Linear(embedding_dim, self.hidden_state_size)\n",
    "        self.Local = nn.GRU(,batch_first=True)\n",
    "        self.Global = nn.GRU(,batch_first=True)\n",
    "        self.Softmax = nn.Softmax()\n",
    "        self.Decoder = nn.Bilinear(embedding_dim, , output_dim)\n",
    "        # TODO: find input and output size of A1 and A2\n",
    "        self.A1 = nn.Linear()\n",
    "        self.A2 = nn.Linear()\n",
    "        self.loss = top1\n",
    "        \n",
    "    def forward(self,x):\n",
    "        user, history, inputs = x\n",
    "        # user shape (1)\n",
    "        # history shape (history_length)\n",
    "        # current shape (seq_length,1)\n",
    "        item_embeds_h = self.ItemEmbedding(history)\n",
    "        # item_embeds_h shape (history_length, embedding_size)\n",
    "        user_embed = self.UserEmbedding(user)\n",
    "        # user_embed shape (1, embedding_size)\n",
    "        dense = self.ActivationFn(self.UserHistory(item_embeds_h))\n",
    "        # dense shape (history_length, hidden_state_size)\n",
    "        alpha1 = self.Softmax(torch.matmul(user_embed,torch.transpose(dense, 0, 1)))\n",
    "        # alpha shape (history_length)\n",
    "        profile = torch.sum(torch.mul(alpha1,torch.transpose(dense,0,1)),1)\n",
    "        # profile shape (hidden_state_size)\n",
    "        # reshape to correct hidden state dimensions\n",
    "        h_0 = torch.reshape(profile,*self.hidden_state_dim)\n",
    "        \n",
    "        # add a batch dimension to the front, necessary for GRU\n",
    "        inputs = inputs[None,:,:]\n",
    "        \n",
    "        out_local, _ = self.Local(inputs,h_0)\n",
    "        out_global, _ = self.Global(inputs,h_0)\n",
    "        # out shape (batch_size, seq_length, hidden_size), containing hidden state output for every step\n",
    "        \n",
    "        A1 = self.A1()\n",
    "        alpha2 = self.ActivationFn(self.A1())\n",
    "        \n",
    "        c_local = torch.cumsum(torch.mul(alpha2,torch.transpose(out_local[1,:,:],0,1)),1)\n",
    "        # c_local shape (hidden_size, sequence length)\n",
    "        \n",
    "        \n",
    "        c = torch.cat(c_global, c_local, dim=2)\n",
    "        out = self.Decoder()\n",
    "        output = self.Softmax(out)\n",
    "        return output\n",
    "    \n",
    "    def alpha2(self,H):\n",
    "        # H shape (batch, sequence, hidden size)\n",
    "        H = H.squeeze()\n",
    "        # H shape (sequence, hidden size)\n",
    "        s = H.shape\n",
    "        alpha = torch.ones(s, dtype=torch.float64, device=device)\n",
    "        \n",
    "        for t in range(H.shape[1]):\n",
    "            A1 = self.A1(H[t])\n",
    "            for j in range(t):\n",
    "                \n",
    "            alpha[1,t] = torch.add(A1,A2)\n",
    "    \n",
    "    def top1(self, yhat):\\n\",\n",
    "        ''' Top1 loss, yhat is vector with softmax probabilities '''\n",
    "        # Not sure if you can just call backward to this, but I think it should work. Code from:\n",
    "        # https://github.com/mquad/hgru4rec/blob/master/src/hgru4rec.py\n",
    "        yhatT = torch.transpose(yhat, 0, 1)\n",
    "        loss = torch.mean(torch.mean(nn.sigmoid( - torch.diag(yhat) + yhatT) + nn.sigmoid(yhat ** 2), dim = 0) - nn.sigmoid(T.diag(yhat ** 2)))\n",
    "        return loss\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
