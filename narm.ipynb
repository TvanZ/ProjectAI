{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "import pickle\n",
    "import math\n",
    "import os\n",
    "import operator\n",
    "import pandas\n",
    "from __future__ import print_function\n",
    "\n",
    "from collections import Counter, OrderedDict, defaultdict, namedtuple\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "from theano import config\n",
    "import theano.tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pandas.read_pickle(\"./data/processedData.pkl\")\n",
    "userList = sample[\"USERID\"].unique()\n",
    "productList = sample[\"PRODUCTID\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "userBase = sample.groupby(['USERID', 'SESSION'])['PRODUCTID'].apply(list).groupby('USERID').apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 67172\n"
     ]
    }
   ],
   "source": [
    "# Here we first define a class that can map a product to an ID (p2i)\n",
    "# and back (i2p).\n",
    "\n",
    "class OrderedCounter(Counter, OrderedDict):\n",
    "    \"\"\"Counter that remembers the order elements are first seen\"\"\"\n",
    "    def __repr__(self):\n",
    "        return '%s(%r)' % (self.__class__.__name__,\n",
    "                      OrderedDict(self))\n",
    "    def __reduce__(self):\n",
    "        return self.__class__, (OrderedDict(self),)\n",
    "\n",
    "\n",
    "class Vocabulary:\n",
    "    \"\"\"A vocabulary, assigns IDs to tokens\"\"\"\n",
    "    def __init__(self):\n",
    "        self.freqs = OrderedCounter()\n",
    "        self.users = []\n",
    "        self.u2i = {}\n",
    "        self.i2u = []\n",
    "        self.p2i = {}\n",
    "        self.i2p = []\n",
    "        self.p2e = {}\n",
    "        self.u2e = {}\n",
    "\n",
    "    def count_product(self, t):\n",
    "        self.freqs[t] += 1\n",
    "    \n",
    "    def count_user(self, t):\n",
    "        self.users.append(t)\n",
    "\n",
    "    def add_product(self, t):\n",
    "        self.p2i[t] = str(len(self.p2i))\n",
    "        self.i2p.append(t) \n",
    "        \n",
    "    def add_user(self, t):\n",
    "        self.u2i[t] = str(len(self.u2i))\n",
    "        self.i2u.append(t)\n",
    "\n",
    "    def build(self, min_freq=0):\n",
    "#         self.add_product(\"<unk>\")  # reserve 0 for <unk> (unknown products (products only occuring in test set))\n",
    "#         self.add_user(\"<unk>\")\n",
    "        tok_freq = list(self.freqs.items())\n",
    "        tok_freq.sort(key=lambda x: x[1], reverse=True)\n",
    "        for tok, freq in tok_freq:\n",
    "            if freq >= min_freq:\n",
    "                self.add_product(tok)\n",
    "        for user in self.users:\n",
    "            self.add_user(user)\n",
    "            \n",
    "            \n",
    "# This process should be deterministic and should have the same result \n",
    "# if run multiple times on the same data set.\n",
    "\n",
    "def build_voc(userList, productList):\n",
    "    v = Vocabulary()\n",
    "    for product in productList:\n",
    "        v.count_product(product)\n",
    "    for user in userList:\n",
    "        v.count_user(user)\n",
    "    v.build()\n",
    "    return v\n",
    "\n",
    "v = build_voc(userList, productList)\n",
    "print(\"Vocabulary size:\", len(v.p2i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 15, 14]\n",
      "\n",
      "[11561, 21435, 15043, 15084, 10699]\n",
      "[2661, 11561, 21435, 15043, 15084, 10699]\n"
     ]
    }
   ],
   "source": [
    "# More efficient create examples function\n",
    "# A simple way to define a class is using namedtuple.\n",
    "Example = namedtuple(\"Example\", [\"inputs\", \"target\"])\n",
    "\n",
    "\n",
    "def f(userid, sessions, train):\n",
    "    #print(sessions)\n",
    "    sessions = [[int(v.p2i.get(t,0)) for t in ses] for ses in sessions if len(ses) > 1]\n",
    "#     if userid == 11905:\n",
    "#         print(sessions)\n",
    "    if train:\n",
    "        object_train = Example(inputs = sessions[-2], target = sessions[-2][1:])\n",
    "        return object_train\n",
    "    else:\n",
    "        return Example(\n",
    "                       inputs = sessions[-1], \n",
    "                       target = sessions[-1][1:])\n",
    "\n",
    "def createExamples(userBase):\n",
    "    ''' Create training and testing set '''\n",
    "    userBase = pandas.DataFrame(userBase)\n",
    "    userBase.reset_index(level = 0, inplace = True)\n",
    "    trainData = [x for x in \n",
    "                 userBase.apply(lambda x: f(x['USERID'], x['PRODUCTID'], True), axis = 1).tolist() \n",
    "                 if x is not None]\n",
    "    testData = [x for x in \n",
    "                userBase.apply(lambda x: f(x['USERID'], x['PRODUCTID'], False), axis = 1).tolist() \n",
    "                if x is not None]\n",
    "    return trainData, testData\n",
    "\n",
    "trainData, testData = createExamples(userBase)\n",
    "\n",
    "\n",
    "narmTrain = ([example.inputs for example in trainData],[example.target for example in trainData]) \n",
    "narmTest = ([example.inputs for example in testData],[example.target for example in testData])\n",
    "\n",
    "print(narmTrain[0][0])\n",
    "print('')\n",
    "print(narmTest[1][1])\n",
    "print(narmTest[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[708]\n",
      "[13588, 708]\n"
     ]
    }
   ],
   "source": [
    "print(narmTrain[1][25])\n",
    "print(narmTrain[0][25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_seqs(iseqs):\n",
    "    out_seqs = []\n",
    "    out_dates = []\n",
    "    labs = []\n",
    "    for seq in iseqs:\n",
    "        for i in range(1, len(seq)):\n",
    "            tar = seq[-i]\n",
    "            labs += [tar]\n",
    "            out_seqs += [seq[:-i]]\n",
    "            out_dates += [0]\n",
    "\n",
    "    return out_seqs, out_dates, labs\n",
    "\n",
    "\n",
    "tr_seqs, tr_dates, tr_labs = process_seqs(narmTrain[0])\n",
    "te_seqs, te_dates, te_labs = process_seqs(narmTest[0])\n",
    "\n",
    "trainData = (tr_seqs, tr_labs)\n",
    "testData = (te_seqs, te_labs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13, 16], [13], [2661, 11561, 21435, 15043, 15084], [2661, 11561, 21435, 15043], [2661, 11561, 21435], [2661, 11561], [2661], [34909, 16183, 15406, 20815, 21377, 956, 3218, 17640, 34910, 826, 34911, 34912, 28019, 6030, 1895, 3139, 25705, 7144, 21379, 15023], [34909, 16183, 15406, 20815, 21377, 956, 3218, 17640, 34910, 826, 34911, 34912, 28019, 6030, 1895, 3139, 25705, 7144, 21379], [34909, 16183, 15406, 20815, 21377, 956, 3218, 17640, 34910, 826, 34911, 34912, 28019, 6030, 1895, 3139, 25705, 7144]]\n",
      "[17, 16, 10699, 15084, 15043, 21435, 11561, 2772, 15023, 21379]\n"
     ]
    }
   ],
   "source": [
    "#Atrain, Btrain = trainData\n",
    "\n",
    "print(te_seqs[0:10])\n",
    "print(te_labs[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "def prepare_data(seqs, labels):\n",
    "    \"\"\"Create the matrices from the datasets.\n",
    "\n",
    "    This pad each sequence to the same lenght: the lenght of the\n",
    "    longuest sequence or maxlen.\n",
    "\n",
    "    if maxlen is set, we will cut all sequence to this maximum\n",
    "    lenght.\n",
    "\n",
    "    This swap the axis!\n",
    "    \"\"\"\n",
    "    # x: a list of sentences\n",
    "\n",
    "    lengths = [len(s) for s in seqs]\n",
    "    n_samples = len(seqs)\n",
    "    maxlen = np.max(lengths)\n",
    "\n",
    "    x = np.zeros((maxlen, n_samples)).astype('int64')\n",
    "    x_mask = np.ones((maxlen, n_samples)).astype(theano.config.floatX)\n",
    "    for idx, s in enumerate(seqs):\n",
    "        x[:lengths[idx], idx] = s\n",
    "\n",
    "    x_mask *= (1 - (x == 0))\n",
    "\n",
    "    return x, x_mask, labels\n",
    "\n",
    "\n",
    "def load_data(valid_portion=0.1, maxlen=19, sort_by_len=False):\n",
    "    '''Loads the dataset\n",
    "\n",
    "    :type path: String\n",
    "    :param path: The path to the dataset (here RSC2015)\n",
    "    :type n_items: int\n",
    "    :param n_items: The number of items.\n",
    "    :type valid_portion: float\n",
    "    :param valid_portion: The proportion of the full train set used for\n",
    "        the validation set.\n",
    "    :type maxlen: None or positive int\n",
    "    :param maxlen: the max sequence length we use in the train/valid set.\n",
    "    :type sort_by_len: bool\n",
    "    :name sort_by_len: Sort by the sequence lenght for the train,\n",
    "        valid and test set. This allow faster execution as it cause\n",
    "        less padding per minibatch. Another mechanism must be used to\n",
    "        shuffle the train set at each epoch.\n",
    "\n",
    "    '''\n",
    "\n",
    "    #############\n",
    "    # LOAD DATA #\n",
    "    #############\n",
    "\n",
    "    # Load the dataset\n",
    "    #path_train_data = './data/processedData.pkl'\n",
    "    #path_test_data = './data/processedData.pkl'\n",
    "\n",
    "    #f1 = open(path_train_data, 'rb')\n",
    "    train_set = trainData\n",
    "    #f1.close()\n",
    "\n",
    "    #f2 = open(path_test_data, 'rb')\n",
    "    test_set = testData\n",
    "    #f2.close()\n",
    "\n",
    "    if maxlen:\n",
    "        new_train_set_x = []\n",
    "        new_train_set_y = []\n",
    "        for x, y in zip(train_set[0], train_set[1]):\n",
    "            if len(x) < maxlen:\n",
    "                new_train_set_x.append(x)\n",
    "                new_train_set_y.append(y)\n",
    "            else:\n",
    "                new_train_set_x.append(x[:maxlen])\n",
    "                new_train_set_y.append(y)\n",
    "        train_set = (new_train_set_x, new_train_set_y)\n",
    "        del new_train_set_x, new_train_set_y\n",
    "\n",
    "        new_test_set_x = []\n",
    "        new_test_set_y = []\n",
    "        for xx, yy in zip(test_set[0], test_set[1]):\n",
    "            if len(xx) < maxlen:\n",
    "                new_test_set_x.append(xx)\n",
    "                new_test_set_y.append(yy)\n",
    "            else:\n",
    "                new_test_set_x.append(xx[:maxlen])\n",
    "                new_test_set_y.append(yy)\n",
    "        test_set = (new_test_set_x, new_test_set_y)\n",
    "        del new_test_set_x, new_test_set_y\n",
    "\n",
    "    # split training set into validation set\n",
    "    train_set_x, train_set_y = train_set\n",
    "    n_samples = len(train_set_x)\n",
    "    sidx = np.arange(n_samples, dtype='int32')\n",
    "    np.random.shuffle(sidx)\n",
    "    n_train = int(np.round(n_samples * (1. - valid_portion)))\n",
    "    valid_set_x = [train_set_x[s] for s in sidx[n_train:]]\n",
    "    valid_set_y = [train_set_y[s] for s in sidx[n_train:]]\n",
    "    train_set_x = [train_set_x[s] for s in sidx[:n_train]]\n",
    "    train_set_y = [train_set_y[s] for s in sidx[:n_train]]\n",
    "\n",
    "    train_set = (train_set_x, train_set_y)\n",
    "    valid_set = (valid_set_x, valid_set_y)\n",
    "\n",
    "    test_set_x, test_set_y = test_set\n",
    "    valid_set_x, valid_set_y = valid_set\n",
    "    train_set_x, train_set_y = train_set\n",
    "\n",
    "#     def len_argsort(seq):\n",
    "#         return sorted(range(len(seq)), key=lambda x: len(seq[x]))\n",
    "\n",
    "#     if sort_by_len:\n",
    "#         sorted_index = len_argsort(test_set_x)\n",
    "#         test_set_x = [test_set_x[i] for i in sorted_index]\n",
    "#         test_set_y = [test_set_y[i] for i in sorted_index]\n",
    "\n",
    "#         sorted_index = len_argsort(valid_set_x)\n",
    "#         valid_set_x = [valid_set_x[i] for i in sorted_index]\n",
    "#         valid_set_y = [valid_set_y[i] for i in sorted_index]\n",
    "\n",
    "    train = (train_set_x, train_set_y)\n",
    "    valid = (valid_set_x, valid_set_y)\n",
    "    test = (test_set_x, test_set_y)\n",
    "\n",
    "    return train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Build NARM model\n",
    "'''\n",
    "\n",
    "\n",
    "datasets = {'rsc2015': (load_data, prepare_data)}\n",
    "\n",
    "#datasets = {'rsc2015': (narmTrain, narmTest)}\n",
    "\n",
    "# Set the random number generators' seeds for consistency\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "def numpy_floatX(data):\n",
    "    return np.asarray(data, dtype=config.floatX)\n",
    "\n",
    "\n",
    "def get_minibatches_idx(n, minibatch_size, shuffle=False):\n",
    "    \"\"\"\n",
    "    Used to shuffle the dataset at each iteration.\n",
    "    \"\"\"\n",
    "\n",
    "    idx_list = np.arange(n, dtype=\"int32\")\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(idx_list)\n",
    "\n",
    "    minibatches = []\n",
    "    minibatch_start = 0\n",
    "    for i in range(n // minibatch_size):\n",
    "        minibatches.append(idx_list[minibatch_start:\n",
    "                                    minibatch_start + minibatch_size])\n",
    "        minibatch_start += minibatch_size\n",
    "\n",
    "    if minibatch_start != n:\n",
    "        # Make a minibatch out of what is left\n",
    "        minibatches.append(idx_list[minibatch_start:])\n",
    "\n",
    "    return zip(range(len(minibatches)), minibatches)\n",
    "\n",
    "\n",
    "def get_dataset(name):\n",
    "    return datasets[name][0], datasets[name][1]\n",
    "\n",
    "\n",
    "def zipp(params, tparams):\n",
    "    \"\"\"\n",
    "    When we reload the model. Needed for the GPU stuff.\n",
    "    \"\"\"\n",
    "    for kk, vv in params.items():\n",
    "        tparams[kk].set_value(vv)\n",
    "\n",
    "\n",
    "def unzip(zipped):\n",
    "    \"\"\"\n",
    "    When we pickle the model. Needed for the GPU stuff.\n",
    "    \"\"\"\n",
    "    new_params = OrderedDict()\n",
    "    for kk, vv in zipped.items():\n",
    "        new_params[kk] = vv.get_value()\n",
    "    return new_params\n",
    "\n",
    "\n",
    "def dropout_layer(state_before, use_noise, trng, drop_p=0.5):\n",
    "    retain = 1. - drop_p\n",
    "    proj = T.switch(use_noise, (state_before * trng.binomial(state_before.shape,\n",
    "                                                             p=retain, n=1,\n",
    "                                                             dtype=state_before.dtype)), state_before * retain)\n",
    "    return proj\n",
    "\n",
    "\n",
    "def _p(pp, name):\n",
    "    return '%s_%s' % (pp, name)\n",
    "\n",
    "\n",
    "def init_params(options):\n",
    "    \"\"\"\n",
    "    Global (not GRU) parameter. For the embeding and the classifier.\n",
    "    \"\"\"\n",
    "    params = OrderedDict()\n",
    "    # embedding\n",
    "    params['Wemb'] = init_weights((options['n_items'], options['dim_proj']))\n",
    "    params = get_layer(options['encoder'])[0](options,\n",
    "                                              params,\n",
    "                                              prefix=options['encoder'])\n",
    "    # attention\n",
    "    params['W_encoder'] = init_weights((options['hidden_units'], options['hidden_units']))\n",
    "    params['W_decoder'] = init_weights((options['hidden_units'], options['hidden_units']))\n",
    "    params['bl_vector'] = init_weights((1, options['hidden_units']))\n",
    "    # classifier\n",
    "    # params['U'] = init_weights((2*options['hidden_units'], options['n_items']))\n",
    "    # params['b'] = np.zeros((options['n_items'],)).astype(config.floatX)\n",
    "    params['bili'] = init_weights((options['dim_proj'], 2 * options['hidden_units']))\n",
    "\n",
    "    return params\n",
    "\n",
    "\n",
    "def load_params(path, params):\n",
    "    pp = np.load(path)\n",
    "    for kk, vv in params.items():\n",
    "        if kk not in pp:\n",
    "            raise Warning('%s is not in the archive' % kk)\n",
    "        params[kk] = pp[kk]\n",
    "\n",
    "    return params\n",
    "\n",
    "\n",
    "def init_tparams(params):\n",
    "    tparams = OrderedDict()\n",
    "    for kk, pp in params.items():\n",
    "        tparams[kk] = theano.shared(params[kk], name=kk)\n",
    "    return tparams\n",
    "\n",
    "\n",
    "def get_layer(name):\n",
    "    fns = layers[name]\n",
    "    return fns\n",
    "\n",
    "\n",
    "def init_weights(shape):\n",
    "    sigma = np.sqrt(2. / shape[0])\n",
    "    return numpy_floatX(np.random.randn(*shape) * sigma)\n",
    "\n",
    "\n",
    "def ortho_weight(ndim):\n",
    "    W = np.random.randn(ndim, ndim)\n",
    "    u, s, v = np.linalg.svd(W)\n",
    "    return u.astype(config.floatX)\n",
    "\n",
    "\n",
    "def param_init_gru(options, params, prefix='gru'):\n",
    "    \"\"\"\n",
    "    Init the GRU parameter:\n",
    "\n",
    "    :see: init_params\n",
    "    \"\"\"\n",
    "    Wxrz = np.concatenate([init_weights((options['dim_proj'], options['hidden_units'])),\n",
    "                           init_weights((options['dim_proj'], options['hidden_units'])),\n",
    "                           init_weights((options['dim_proj'], options['hidden_units']))], axis=1)\n",
    "    params[_p(prefix, 'Wxrz')] = Wxrz\n",
    "\n",
    "    Urz = np.concatenate([ortho_weight(options['hidden_units']),\n",
    "                          ortho_weight(options['hidden_units'])], axis=1)\n",
    "    params[_p(prefix, 'Urz')] = Urz\n",
    "\n",
    "    Uh = ortho_weight(options['hidden_units'])\n",
    "    params[_p(prefix, 'Uh')] = Uh\n",
    "\n",
    "    b = np.zeros((3 * options['hidden_units'],))\n",
    "    params[_p(prefix, 'b')] = b.astype(config.floatX)\n",
    "    return params\n",
    "\n",
    "\n",
    "def gru_layer(tparams, state_below, options, prefix='gru', mask=None):\n",
    "    nsteps = state_below.shape[0]\n",
    "    if state_below.ndim == 3:\n",
    "        n_samples = state_below.shape[1]\n",
    "    else:\n",
    "        n_samples = 1\n",
    "\n",
    "    assert mask is not None\n",
    "\n",
    "    def _slice(_x, n, dim):\n",
    "        if _x.ndim == 3:\n",
    "            return _x[:, :, n * dim:(n + 1) * dim]\n",
    "        return _x[:, n * dim:(n + 1) * dim]\n",
    "\n",
    "    def _step(m_, x_, h_):\n",
    "        preact = T.dot(h_, tparams[_p(prefix, 'Urz')])\n",
    "        preact += x_[:, 0:2 * options['hidden_units']]\n",
    "\n",
    "        z = T.nnet.hard_sigmoid(_slice(preact, 0, options['hidden_units']))\n",
    "        r = T.nnet.hard_sigmoid(_slice(preact, 1, options['hidden_units']))\n",
    "        h = T.tanh(T.dot((h_ * r), tparams[_p(prefix, 'Uh')]) + _slice(x_, 2, options['hidden_units']))\n",
    "\n",
    "        h = (1.0 - z) * h_ + z * h\n",
    "        h = m_[:, None] * h + (1. - m_)[:, None] * h_\n",
    "\n",
    "        return h\n",
    "\n",
    "    state_below = (T.dot(state_below, tparams[_p(prefix, 'Wxrz')]) +\n",
    "                   tparams[_p(prefix, 'b')])\n",
    "\n",
    "    hidden_units = options['hidden_units']\n",
    "    rval, updates = theano.scan(_step,\n",
    "                                sequences=[mask, state_below],\n",
    "                                outputs_info=T.alloc(numpy_floatX(0.), n_samples, hidden_units),\n",
    "                                name=_p(prefix, '_layers'),\n",
    "                                n_steps=nsteps)\n",
    "    return rval\n",
    "\n",
    "layers = {'gru': (param_init_gru, gru_layer)}\n",
    "\n",
    "\n",
    "def adam(loss, all_params, learning_rate=0.001, b1=0.9, b2=0.999, e=1e-8, gamma=1-1e-8):\n",
    "    \"\"\"\n",
    "    ADAM update rules\n",
    "    Default values are taken from [Kingma2014]\n",
    "\n",
    "    References:\n",
    "    [Kingma2014] Kingma, Diederik, and Jimmy Ba.\n",
    "    \"Adam: A Method for Stochastic Optimization.\"\n",
    "    arXiv preprint arXiv:1412.6980 (2014).\n",
    "    http://arxiv.org/pdf/1412.6980v4.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    updates = OrderedDict()\n",
    "    all_grads = theano.grad(loss, all_params)\n",
    "    alpha = learning_rate\n",
    "    t = theano.shared(np.float32(1))\n",
    "    b1_t = b1*gamma**(t-1)   #(Decay the first moment running average coefficient)\n",
    "\n",
    "    for theta_previous, g in zip(all_params, all_grads):\n",
    "        m_previous = theano.shared(np.zeros(theta_previous.get_value().shape, dtype=config.floatX))\n",
    "        v_previous = theano.shared(np.zeros(theta_previous.get_value().shape, dtype=config.floatX))\n",
    "\n",
    "        m = b1_t*m_previous + (1 - b1_t)*g  # (Update biased first moment estimate)\n",
    "        v = b2*v_previous + (1 - b2)*g**2   # (Update biased second raw moment estimate)\n",
    "        m_hat = m / (1-b1**t)               # (Compute bias-corrected first moment estimate)\n",
    "        v_hat = v / (1-b2**t)               # (Compute bias-corrected second raw moment estimate)\n",
    "        theta = theta_previous - (alpha * m_hat) / (T.sqrt(v_hat) + e) #(Update parameters)\n",
    "\n",
    "        updates[m_previous] = m\n",
    "        updates[v_previous] = v\n",
    "        updates[theta_previous] = theta\n",
    "    updates[t] = t + 1.\n",
    "\n",
    "    return updates\n",
    "\n",
    "\n",
    "def build_model(tparams, options):\n",
    "    trng = RandomStreams(SEED)\n",
    "\n",
    "    # Used for dropout.\n",
    "    use_noise = theano.shared(numpy_floatX(0.))\n",
    "\n",
    "    x = T.matrix('x', dtype='int64')\n",
    "    mask = T.matrix('mask', dtype=config.floatX)\n",
    "    y = T.vector('y', dtype='int64')\n",
    "\n",
    "    n_timesteps = x.shape[0]\n",
    "    n_samples = x.shape[1]\n",
    "\n",
    "    emb = tparams['Wemb'][x.flatten()].reshape([n_timesteps,\n",
    "                                                n_samples,\n",
    "                                                options['dim_proj']])\n",
    "    if options['use_dropout']:\n",
    "        emb = dropout_layer(emb, use_noise, trng, drop_p=0.25)\n",
    "\n",
    "    proj = get_layer(options['encoder'])[1](tparams, emb, options,\n",
    "                                            prefix=options['encoder'],\n",
    "                                            mask=mask)\n",
    "\n",
    "    def compute_alpha(state1, state2):\n",
    "        tmp = T.nnet.hard_sigmoid(T.dot(tparams['W_encoder'], state1.T) + T.dot(tparams['W_decoder'], state2.T))\n",
    "        alpha = T.dot(tparams['bl_vector'], tmp)\n",
    "        res = T.sum(alpha, axis=0)\n",
    "        return res\n",
    "\n",
    "    last_h = proj[-1]\n",
    "\n",
    "    sim_matrix, _ = theano.scan(\n",
    "        fn=compute_alpha,\n",
    "        sequences=proj,\n",
    "        non_sequences=proj[-1]\n",
    "    )\n",
    "    att = T.nnet.softmax(sim_matrix.T * mask.T) * mask.T\n",
    "    p = att.sum(axis=1)[:, None]\n",
    "    weight = att / p\n",
    "    atttention_proj = (proj * weight.T[:, :, None]).sum(axis=0)\n",
    "\n",
    "    proj = T.concatenate([atttention_proj, last_h], axis=1)\n",
    "\n",
    "    if options['use_dropout']:\n",
    "        proj = dropout_layer(proj, use_noise, trng, drop_p=0.5)\n",
    "\n",
    "    ytem = T.dot(tparams['Wemb'], tparams['bili'])\n",
    "    pred = T.nnet.softmax(T.dot(proj, ytem.T))\n",
    "    # pred = T.nnet.softmax(T.dot(proj, tparams['U']) + tparams['b'])\n",
    "\n",
    "    f_pred_prob = theano.function([x, mask], pred, name='f_pred_prob')\n",
    "    # f_weight = theano.function([x, mask], weight, name='f_weight')\n",
    "\n",
    "    off = 1e-8\n",
    "    if pred.dtype == 'float16':\n",
    "        off = 1e-6\n",
    "\n",
    "    cost = -T.log(pred[T.arange(n_samples), y] + off).mean()\n",
    "\n",
    "    return use_noise, x, mask, y, f_pred_prob, cost\n",
    "\n",
    "\n",
    "def pred_evaluation(f_pred_prob, prepare_data, data, iterator):\n",
    "    \"\"\"\n",
    "    Compute recall@20 and mrr@20\n",
    "    f_pred_prob: Theano fct computing the prediction\n",
    "    prepare_data: usual prepare_data for that dataset.\n",
    "    \"\"\"\n",
    "    recall = 0.0\n",
    "    mrr = 0.0\n",
    "    evalutation_point_count = 0\n",
    "    ranks = \"never entered for-loop\"\n",
    "    # pred_res = []\n",
    "    # att = []\n",
    "\n",
    "    for _, valid_index in iterator:\n",
    "        x, mask, y = prepare_data([data[0][t] for t in valid_index], [data[1][t] for t in valid_index])\n",
    "        preds = f_pred_prob(x, mask)\n",
    "        # weights = f_weight(x, mask)\n",
    "        targets = y\n",
    "\n",
    "        ranks = (preds.T > np.diag(preds.T[targets])).sum(axis=0) + 1\n",
    "#         if math.isnan(ranks):\n",
    "#             print(preds)\n",
    "#             print(targets)\n",
    "        rank_ok = (ranks <= 20)\n",
    "        # pred_res += list(rank_ok)\n",
    "        recall += rank_ok.sum()\n",
    "        mrr += (1.0 / ranks[rank_ok]).sum()\n",
    "        evalutation_point_count += len(ranks)\n",
    "        # att.append(weights)\n",
    "\n",
    "    recall = numpy_floatX(recall) / evalutation_point_count\n",
    "    mrr = numpy_floatX(mrr) / evalutation_point_count\n",
    "    eval_score = (recall, mrr)\n",
    "\n",
    "    # ff = open('/storage/lijing/mydataset/res_attention_correct.pkl', 'wb')\n",
    "    # pickle.dump(pred_res, ff)\n",
    "    # ff.close()\n",
    "    # ff2 = open('/storage/lijing/mydataset/attention_weights.pkl', 'wb')\n",
    "    # pickle.dump(att, ff2)\n",
    "    # ff2.close()\n",
    "\n",
    "    return eval_score\n",
    "\n",
    "\n",
    "def train_gru(\n",
    "    dim_proj=50,  # word embeding dimension\n",
    "    hidden_units=100,  # GRU number of hidden units.\n",
    "    patience=100,  # Number of epoch to wait before early stop if no progress\n",
    "    max_epochs=30,  # The maximum number of epoch to run\n",
    "    dispFreq=100,  # Display to stdout the training progress every N updates\n",
    "    lrate=0.001,  # Learning rate\n",
    "    n_items=37484,  # Vocabulary size\n",
    "    encoder='gru',  # TODO: can be removed must be gru.\n",
    "    saveto='narm_model.npz',  # The best model will be saved there\n",
    "    is_valid=True,  # Compute the validation error after this number of update.\n",
    "    is_save=False,  # Save the parameters after every saveFreq updates\n",
    "    batch_size=512,  # The batch size during training.\n",
    "    valid_batch_size=512,  # The batch size used for validation/test set.\n",
    "    dataset='rsc2015',\n",
    "\n",
    "    # Parameter for extra option\n",
    "    use_dropout=True,  # if False slightly faster, but worst test error\n",
    "                       # This frequently need a bigger model.\n",
    "    reload_model=None,  # Path to a saved model we want to start from.\n",
    "    test_size=-1,  # If >0, we keep only this number of test example.\n",
    "):\n",
    "\n",
    "    # Model options\n",
    "    model_options = locals().copy()\n",
    "    print(\"model options\", model_options)\n",
    "\n",
    "    load_data, prepare_data = get_dataset(dataset)\n",
    "\n",
    "    print('Loading data')\n",
    "    train, valid, test = load_data()\n",
    "\n",
    "    print('Building model')\n",
    "    # This create the initial parameters as numpy ndarrays.\n",
    "    # Dict name (string) -> numpy ndarray\n",
    "    params = init_params(model_options)\n",
    "\n",
    "    if reload_model:\n",
    "        load_params('gru_model.npz', params)\n",
    "\n",
    "    # This create Theano Shared Variable from the parameters.\n",
    "    # Dict name (string) -> Theano Tensor Shared Variable\n",
    "    # params and tparams have different copy of the weights.\n",
    "    tparams = init_tparams(params)\n",
    "\n",
    "    # use_noise is for dropout\n",
    "    (use_noise, x, mask,\n",
    "     y, f_pred_prob, cost) = build_model(tparams, model_options)\n",
    "\n",
    "    all_params = list(tparams.values())\n",
    "\n",
    "    updates = adam(cost, all_params, lrate)\n",
    "\n",
    "    train_function = theano.function(inputs=[x, mask, y], outputs=cost, updates=updates)\n",
    "\n",
    "    print('Optimization')\n",
    "\n",
    "    kf_valid = get_minibatches_idx(len(valid[0]), valid_batch_size)\n",
    "    kf_test = get_minibatches_idx(len(test[0]), valid_batch_size)\n",
    "\n",
    "    print(\"%d train examples\" % len(train[0]))\n",
    "    print(\"%d valid examples\" % len(valid[0]))\n",
    "    print(\"%d test examples\" % len(test[0]))\n",
    "\n",
    "    history_errs = []\n",
    "    history_vali = []\n",
    "    best_p = None\n",
    "    bad_count = 0\n",
    "\n",
    "    uidx = 0  # the number of update done\n",
    "    estop = False  # early stop\n",
    "\n",
    "    try:\n",
    "        for eidx in range(max_epochs):\n",
    "            start_time = time.time()\n",
    "            n_samples = 0\n",
    "            epoch_loss = []\n",
    "\n",
    "            # Get new shuffled index for the training set.\n",
    "            kf = get_minibatches_idx(len(train[0]), batch_size, shuffle=True)\n",
    "\n",
    "            for _, train_index in kf:\n",
    "                uidx += 1\n",
    "                use_noise.set_value(1.)\n",
    "\n",
    "                # Select the random examples for this minibatch\n",
    "                y = [train[1][t] for t in train_index]\n",
    "                x = [train[0][t]for t in train_index]\n",
    "                \n",
    "                \n",
    "                # Get the data in numpy.ndarray format\n",
    "                # This swap the axis!\n",
    "                # Return something of shape (minibatch maxlen, n samples)\n",
    "                x, mask, y = prepare_data(x, y)\n",
    "                n_samples += x.shape[1]\n",
    "\n",
    "                loss = train_function(x, mask, y)\n",
    "                epoch_loss.append(loss)\n",
    "\n",
    "                if np.isnan(loss) or np.isinf(loss):\n",
    "                    print('bad loss detected: ', loss)\n",
    "                    return 1., 1., 1.\n",
    "\n",
    "                if np.mod(uidx, dispFreq) == 0:\n",
    "                    print('Epoch ', eidx, 'Update ', uidx, 'Loss ', np.mean(epoch_loss))\n",
    "\n",
    "            if saveto and is_save:\n",
    "                print('Saving...')\n",
    "\n",
    "                if best_p is not None:\n",
    "                    params = best_p\n",
    "                else:\n",
    "                    params = unzip(tparams)\n",
    "                np.savez(saveto, history_errs=history_errs, **params)\n",
    "                print('Saving done')\n",
    "\n",
    "            if is_valid:\n",
    "                use_noise.set_value(0.)\n",
    "                kf_valid = get_minibatches_idx(len(valid[0]), valid_batch_size)\n",
    "                kf_test = get_minibatches_idx(len(test[0]), valid_batch_size)\n",
    "\n",
    "                valid_evaluation = pred_evaluation(f_pred_prob, prepare_data, valid, kf_valid)\n",
    "                test_evaluation = pred_evaluation(f_pred_prob, prepare_data, test, kf_test)\n",
    "                history_errs.append([valid_evaluation, test_evaluation])\n",
    "\n",
    "                if best_p is None or valid_evaluation[0] >= np.array(history_vali).max():\n",
    "\n",
    "                    best_p = unzip(tparams)\n",
    "                    print('Best perfomance updated!')\n",
    "                    bad_count = 0\n",
    "\n",
    "                print('Valid Recall@20:', valid_evaluation[0], '   Valid Mrr@20:', valid_evaluation[1],\n",
    "                      '\\nTest Recall@20', test_evaluation[0], '   Test Mrr@20:', test_evaluation[1])\n",
    "\n",
    "                if len(history_vali) > 10 and valid_evaluation[0] <= np.array(history_vali).max():\n",
    "                    bad_count += 1\n",
    "                    print('===========================>Bad counter: ' + str(bad_count))\n",
    "                    print('current validation recall: ' + str(valid_evaluation[0]) +\n",
    "                          '      history max recall:' + str(np.array(history_vali).max()))\n",
    "                    if bad_count > patience:\n",
    "                        print('Early Stop!')\n",
    "                        estop = True\n",
    "\n",
    "                history_vali.append(valid_evaluation[0])\n",
    "\n",
    "            end_time = time.time()\n",
    "            print('Seen %d samples' % n_samples)\n",
    "            print(('This epoch took %.1fs' % (end_time - start_time)), file=sys.stderr)\n",
    "\n",
    "            if estop:\n",
    "                break\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Training interupted\")\n",
    "\n",
    "    if best_p is not None:\n",
    "        zipp(best_p, tparams)\n",
    "    else:\n",
    "        best_p = unzip(tparams)\n",
    "\n",
    "    use_noise.set_value(0.)\n",
    "    kf_valid = get_minibatches_idx(len(valid[0]), valid_batch_size)\n",
    "    kf_test = get_minibatches_idx(len(test[0]), valid_batch_size)\n",
    "    valid_evaluation = pred_evaluation(f_pred_prob, prepare_data, valid, kf_valid)\n",
    "    test_evaluation = pred_evaluation(f_pred_prob,  prepare_data, test, kf_test)\n",
    "\n",
    "    print('=================Best performance=================')\n",
    "    print('Valid Recall@20:', valid_evaluation[0], '   Valid Mrr@20:', valid_evaluation[1],\n",
    "          '\\nTest Recall@20', test_evaluation[0], '   Test Mrr@20:', test_evaluation[1])\n",
    "    print('==================================================')\n",
    "    if saveto and is_save:\n",
    "        np.savez('Best_performance', valid_evaluation=valid_evaluation, test_evaluation=test_evaluation, history_errs=history_errs,\n",
    "                 **best_p)\n",
    "\n",
    "    return valid_evaluation, test_evaluation\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     # See function train for all possible parameter and there definition.\n",
    "#     eval_valid, eval_test = train_gru(max_epochs=10,test_size=-1)\n",
    "    \n",
    "    \n",
    "    \n",
    "#    dim_proj=50,  # word embeding dimension\n",
    "#     hidden_units=100,  # GRU number of hidden units.\n",
    "#     patience=100,  # Number of epoch to wait before early stop if no progress\n",
    "#     max_epochs=30,  # The maximum number of epoch to run\n",
    "#     dispFreq=100,  # Display to stdout the training progress every N updates\n",
    "#     lrate=0.001,  # Learning rate\n",
    "#     n_items=37484,  # Vocabulary size\n",
    "#     encoder='gru',  # TODO: can be removed must be gru.\n",
    "#     saveto='gru_model.npz',  # The best model will be saved there\n",
    "#     is_valid=True,  # Compute the validation error after this number of update.\n",
    "#     is_save=False,  # Save the parameters after every saveFreq updates\n",
    "#     batch_size=512,  # The batch size during training.\n",
    "#     valid_batch_size=512,  # The batch size used for validation/test set.\n",
    "#     dataset='rsc2015',\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     # See function train for all possible parameter and there definition.\n",
    "#     eval_valid, eval_test = train_gru(max_epochs=10,test_size=-1, reload_model=\"./narm_model.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_projL = [10,20,30,40,50,60]\n",
    "lrateL = [0.001, 0.002, 0.003, 0.004]\n",
    "n_itemsL = 67172\n",
    "\n",
    "def gridsearch():\n",
    "    best_option = ()\n",
    "    best_eval_test = 0\n",
    "    for dim_proj in dim_projL:\n",
    "        for lrate in lrateL:\n",
    "            eval_valid, eval_test = train_gru(dim_proj=dim_proj, hidden_units=dim_proj*2, max_epochs=1, lrate=lrate, n_items=n_itemsL)\n",
    "            if eval_test[0] > best_eval_test:\n",
    "                best_option = (dim_proj, lrate)\n",
    "                best_eval_test = eval_test[0]\n",
    "    \n",
    "    best_dim_proj, best_lrate = best_option\n",
    "    eval_valid, eval_test = train_gru(dim_proj=best_dim_proj,\n",
    "                                      hidden_units=dim_proj*2, \n",
    "                                      max_epochs=10, \n",
    "                                      lrate = best_lrate, \n",
    "                                      n_items=n_itemsL, \n",
    "                                      is_save=True)\n",
    "            \n",
    "            \n",
    "    return best_option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model options {'dim_proj': 10, 'hidden_units': 20, 'patience': 100, 'max_epochs': 1, 'dispFreq': 100, 'lrate': 0.001, 'n_items': 67172, 'encoder': 'gru', 'saveto': 'narm_model.npz', 'is_valid': True, 'is_save': False, 'batch_size': 512, 'valid_batch_size': 512, 'dataset': 'rsc2015', 'use_dropout': True, 'reload_model': None, 'test_size': -1}\n",
      "Loading data\n",
      "Building model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock /home/sietze/.theano/compiledir_Linux-4.15--generic-x86_64-with-debian-buster-sid-x86_64-3.7.0-64/lock_dir/lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization\n",
      "101436 train examples\n",
      "11271 valid examples\n",
      "101849 test examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sietze/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 Update  100 Loss  9.11084519515994\n",
      "Best perfomance updated!\n",
      "Valid Recall@20: 0.8087126253216219    Valid Mrr@20: 0.20863360841508957 \n",
      "Test Recall@20 0.8287562960853813    Test Mrr@20: 0.21677733511516148\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 579.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Best performance=================\n",
      "Valid Recall@20: 0.8087126253216219    Valid Mrr@20: 0.20863360841508957 \n",
      "Test Recall@20 0.8287562960853813    Test Mrr@20: 0.21677733511516148\n",
      "==================================================\n",
      "model options {'dim_proj': 10, 'hidden_units': 20, 'patience': 100, 'max_epochs': 1, 'dispFreq': 100, 'lrate': 0.002, 'n_items': 67172, 'encoder': 'gru', 'saveto': 'narm_model.npz', 'is_valid': True, 'is_save': False, 'batch_size': 512, 'valid_batch_size': 512, 'dataset': 'rsc2015', 'use_dropout': True, 'reload_model': None, 'test_size': -1}\n",
      "Loading data\n",
      "Building model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock /home/sietze/.theano/compiledir_Linux-4.15--generic-x86_64-with-debian-buster-sid-x86_64-3.7.0-64/lock_dir/lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization\n",
      "101436 train examples\n",
      "11271 valid examples\n",
      "101849 test examples\n",
      "Epoch  0 Update  100 Loss  7.338937913147305\n",
      "Best perfomance updated!\n",
      "Valid Recall@20: 0.8103096442196788    Valid Mrr@20: 0.2312097127660913 \n",
      "Test Recall@20 0.8301406984850122    Test Mrr@20: 0.2483260562597549\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 344.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Best performance=================\n",
      "Valid Recall@20: 0.8103096442196788    Valid Mrr@20: 0.2312097127660913 \n",
      "Test Recall@20 0.8301406984850122    Test Mrr@20: 0.2483260562597549\n",
      "==================================================\n",
      "model options {'dim_proj': 10, 'hidden_units': 20, 'patience': 100, 'max_epochs': 1, 'dispFreq': 100, 'lrate': 0.003, 'n_items': 67172, 'encoder': 'gru', 'saveto': 'narm_model.npz', 'is_valid': True, 'is_save': False, 'batch_size': 512, 'valid_batch_size': 512, 'dataset': 'rsc2015', 'use_dropout': True, 'reload_model': None, 'test_size': -1}\n",
      "Loading data\n",
      "Building model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock /home/sietze/.theano/compiledir_Linux-4.15--generic-x86_64-with-debian-buster-sid-x86_64-3.7.0-64/lock_dir/lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization\n",
      "101436 train examples\n",
      "11271 valid examples\n",
      "101849 test examples\n",
      "Epoch  0 Update  100 Loss  6.158822769421386\n",
      "Best perfomance updated!\n",
      "Valid Recall@20: 0.8119066631177357    Valid Mrr@20: 0.2443780627923273 \n",
      "Test Recall@20 0.8323400327936455    Test Mrr@20: 0.2564530361351625\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 362.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Best performance=================\n",
      "Valid Recall@20: 0.8119066631177357    Valid Mrr@20: 0.2443780627923273 \n",
      "Test Recall@20 0.8323400327936455    Test Mrr@20: 0.2564530361351625\n",
      "==================================================\n",
      "model options {'dim_proj': 10, 'hidden_units': 20, 'patience': 100, 'max_epochs': 1, 'dispFreq': 100, 'lrate': 0.004, 'n_items': 67172, 'encoder': 'gru', 'saveto': 'narm_model.npz', 'is_valid': True, 'is_save': False, 'batch_size': 512, 'valid_batch_size': 512, 'dataset': 'rsc2015', 'use_dropout': True, 'reload_model': None, 'test_size': -1}\n",
      "Loading data\n",
      "Building model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock /home/sietze/.theano/compiledir_Linux-4.15--generic-x86_64-with-debian-buster-sid-x86_64-3.7.0-64/lock_dir/lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization\n",
      "101436 train examples\n",
      "11271 valid examples\n",
      "101849 test examples\n",
      "Epoch  0 Update  100 Loss  5.741115854714622\n",
      "Best perfomance updated!\n",
      "Valid Recall@20: 0.8113743234850501    Valid Mrr@20: 0.2928358507698126 \n",
      "Test Recall@20 0.8301406984850122    Test Mrr@20: 0.3101031345735014\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 343.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Best performance=================\n",
      "Valid Recall@20: 0.8113743234850501    Valid Mrr@20: 0.2928358507698126 \n",
      "Test Recall@20 0.8301406984850122    Test Mrr@20: 0.3101031345735014\n",
      "==================================================\n",
      "model options {'dim_proj': 20, 'hidden_units': 40, 'patience': 100, 'max_epochs': 1, 'dispFreq': 100, 'lrate': 0.001, 'n_items': 67172, 'encoder': 'gru', 'saveto': 'narm_model.npz', 'is_valid': True, 'is_save': False, 'batch_size': 512, 'valid_batch_size': 512, 'dataset': 'rsc2015', 'use_dropout': True, 'reload_model': None, 'test_size': -1}\n",
      "Loading data\n",
      "Building model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock /home/sietze/.theano/compiledir_Linux-4.15--generic-x86_64-with-debian-buster-sid-x86_64-3.7.0-64/lock_dir/lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization\n",
      "101436 train examples\n",
      "11271 valid examples\n",
      "101849 test examples\n",
      "Epoch  0 Update  100 Loss  7.545156663403876\n",
      "Best perfomance updated!\n",
      "Valid Recall@20: 0.8192706947032207    Valid Mrr@20: 0.24492059742600322 \n",
      "Test Recall@20 0.8323400327936455    Test Mrr@20: 0.25524626546428314\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 376.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Best performance=================\n",
      "Valid Recall@20: 0.8192706947032207    Valid Mrr@20: 0.24492059742600322 \n",
      "Test Recall@20 0.8323400327936455    Test Mrr@20: 0.25524626546428314\n",
      "==================================================\n",
      "model options {'dim_proj': 20, 'hidden_units': 40, 'patience': 100, 'max_epochs': 1, 'dispFreq': 100, 'lrate': 0.002, 'n_items': 67172, 'encoder': 'gru', 'saveto': 'narm_model.npz', 'is_valid': True, 'is_save': False, 'batch_size': 512, 'valid_batch_size': 512, 'dataset': 'rsc2015', 'use_dropout': True, 'reload_model': None, 'test_size': -1}\n",
      "Loading data\n",
      "Building model\n",
      "Optimization\n",
      "101436 train examples\n",
      "11271 valid examples\n",
      "101849 test examples\n",
      "Epoch  0 Update  100 Loss  6.0516006578227\n",
      "Best perfomance updated!\n",
      "Valid Recall@20: 0.8129713423831071    Valid Mrr@20: 0.3636351342572484 \n",
      "Test Recall@20 0.8236114247562568    Test Mrr@20: 0.3902690590192089\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 376.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Best performance=================\n",
      "Valid Recall@20: 0.8129713423831071    Valid Mrr@20: 0.3636351342572484 \n",
      "Test Recall@20 0.8236114247562568    Test Mrr@20: 0.3902690590192089\n",
      "==================================================\n",
      "model options {'dim_proj': 20, 'hidden_units': 40, 'patience': 100, 'max_epochs': 1, 'dispFreq': 100, 'lrate': 0.003, 'n_items': 67172, 'encoder': 'gru', 'saveto': 'narm_model.npz', 'is_valid': True, 'is_save': False, 'batch_size': 512, 'valid_batch_size': 512, 'dataset': 'rsc2015', 'use_dropout': True, 'reload_model': None, 'test_size': -1}\n",
      "Loading data\n",
      "Building model\n",
      "Optimization\n",
      "101436 train examples\n",
      "11271 valid examples\n",
      "101849 test examples\n",
      "Epoch  0 Update  100 Loss  5.291391805280939\n",
      "Best perfomance updated!\n",
      "Valid Recall@20: 0.8528968148345311    Valid Mrr@20: 0.4243507765559893 \n",
      "Test Recall@20 0.8673722864240199    Test Mrr@20: 0.4463108482769604\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 373.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Best performance=================\n",
      "Valid Recall@20: 0.8528968148345311    Valid Mrr@20: 0.4243507765559893 \n",
      "Test Recall@20 0.8673722864240199    Test Mrr@20: 0.4463108482769604\n",
      "==================================================\n",
      "model options {'dim_proj': 20, 'hidden_units': 40, 'patience': 100, 'max_epochs': 1, 'dispFreq': 100, 'lrate': 0.004, 'n_items': 67172, 'encoder': 'gru', 'saveto': 'narm_model.npz', 'is_valid': True, 'is_save': False, 'batch_size': 512, 'valid_batch_size': 512, 'dataset': 'rsc2015', 'use_dropout': True, 'reload_model': None, 'test_size': -1}\n",
      "Loading data\n",
      "Building model\n",
      "Optimization\n",
      "101436 train examples\n",
      "11271 valid examples\n",
      "101849 test examples\n",
      "Epoch  0 Update  100 Loss  4.922423156146292\n",
      "Best perfomance updated!\n",
      "Valid Recall@20: 0.8820867713601278    Valid Mrr@20: 0.5489041552151814 \n",
      "Test Recall@20 0.8933813783149565    Test Mrr@20: 0.5708053918408655\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 375.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Best performance=================\n",
      "Valid Recall@20: 0.8820867713601278    Valid Mrr@20: 0.5489041552151814 \n",
      "Test Recall@20 0.8933813783149565    Test Mrr@20: 0.5708053918408655\n",
      "==================================================\n",
      "model options {'dim_proj': 30, 'hidden_units': 60, 'patience': 100, 'max_epochs': 1, 'dispFreq': 100, 'lrate': 0.001, 'n_items': 67172, 'encoder': 'gru', 'saveto': 'narm_model.npz', 'is_valid': True, 'is_save': False, 'batch_size': 512, 'valid_batch_size': 512, 'dataset': 'rsc2015', 'use_dropout': True, 'reload_model': None, 'test_size': -1}\n",
      "Loading data\n",
      "Building model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock /home/sietze/.theano/compiledir_Linux-4.15--generic-x86_64-with-debian-buster-sid-x86_64-3.7.0-64/lock_dir/lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization\n",
      "101436 train examples\n",
      "11271 valid examples\n",
      "101849 test examples\n",
      "Epoch  0 Update  100 Loss  6.839676670007075\n",
      "Best perfomance updated!\n",
      "Valid Recall@20: 0.8253038772069914    Valid Mrr@20: 0.3410031684004788 \n",
      "Test Recall@20 0.8430814244617031    Test Mrr@20: 0.3617258497311919\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 408.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Best performance=================\n",
      "Valid Recall@20: 0.8253038772069914    Valid Mrr@20: 0.3410031684004788 \n",
      "Test Recall@20 0.8430814244617031    Test Mrr@20: 0.3617258497311919\n",
      "==================================================\n",
      "model options {'dim_proj': 30, 'hidden_units': 60, 'patience': 100, 'max_epochs': 1, 'dispFreq': 100, 'lrate': 0.002, 'n_items': 67172, 'encoder': 'gru', 'saveto': 'narm_model.npz', 'is_valid': True, 'is_save': False, 'batch_size': 512, 'valid_batch_size': 512, 'dataset': 'rsc2015', 'use_dropout': True, 'reload_model': None, 'test_size': -1}\n",
      "Loading data\n",
      "Building model\n",
      "Optimization\n",
      "101436 train examples\n",
      "11271 valid examples\n",
      "101849 test examples\n",
      "Epoch  0 Update  100 Loss  5.513074505623614\n",
      "Best perfomance updated!\n",
      "Valid Recall@20: 0.8654955194747582    Valid Mrr@20: 0.4856914538238501 \n",
      "Test Recall@20 0.8797533603668175    Test Mrr@20: 0.5094566483391051\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 405.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Best performance=================\n",
      "Valid Recall@20: 0.8654955194747582    Valid Mrr@20: 0.4856914538238501 \n",
      "Test Recall@20 0.8797533603668175    Test Mrr@20: 0.5094566483391051\n",
      "==================================================\n",
      "model options {'dim_proj': 30, 'hidden_units': 60, 'patience': 100, 'max_epochs': 1, 'dispFreq': 100, 'lrate': 0.003, 'n_items': 67172, 'encoder': 'gru', 'saveto': 'narm_model.npz', 'is_valid': True, 'is_save': False, 'batch_size': 512, 'valid_batch_size': 512, 'dataset': 'rsc2015', 'use_dropout': True, 'reload_model': None, 'test_size': -1}\n",
      "Loading data\n",
      "Building model\n",
      "Optimization\n",
      "101436 train examples\n",
      "11271 valid examples\n",
      "101849 test examples\n",
      "Epoch  0 Update  100 Loss  4.953907090781563\n",
      "Best perfomance updated!\n",
      "Valid Recall@20: 0.8874988909590986    Valid Mrr@20: 0.583577044586916 \n",
      "Test Recall@20 0.8996553721686026    Test Mrr@20: 0.6066501320278418\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 406.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Best performance=================\n",
      "Valid Recall@20: 0.8874988909590986    Valid Mrr@20: 0.583577044586916 \n",
      "Test Recall@20 0.8996553721686026    Test Mrr@20: 0.6066501320278418\n",
      "==================================================\n",
      "model options {'dim_proj': 30, 'hidden_units': 60, 'patience': 100, 'max_epochs': 1, 'dispFreq': 100, 'lrate': 0.004, 'n_items': 67172, 'encoder': 'gru', 'saveto': 'narm_model.npz', 'is_valid': True, 'is_save': False, 'batch_size': 512, 'valid_batch_size': 512, 'dataset': 'rsc2015', 'use_dropout': True, 'reload_model': None, 'test_size': -1}\n",
      "Loading data\n",
      "Building model\n",
      "Optimization\n",
      "101436 train examples\n",
      "11271 valid examples\n",
      "101849 test examples\n",
      "Epoch  0 Update  100 Loss  4.622795745672263\n",
      "Best perfomance updated!\n",
      "Valid Recall@20: 0.8953952621772691    Valid Mrr@20: 0.5655958743500801 \n",
      "Test Recall@20 0.901501242034777    Test Mrr@20: 0.5845206482562955\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 409.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Best performance=================\n",
      "Valid Recall@20: 0.8953952621772691    Valid Mrr@20: 0.5655958743500801 \n",
      "Test Recall@20 0.901501242034777    Test Mrr@20: 0.5845206482562955\n",
      "==================================================\n",
      "model options {'dim_proj': 40, 'hidden_units': 80, 'patience': 100, 'max_epochs': 1, 'dispFreq': 100, 'lrate': 0.001, 'n_items': 67172, 'encoder': 'gru', 'saveto': 'narm_model.npz', 'is_valid': True, 'is_save': False, 'batch_size': 512, 'valid_batch_size': 512, 'dataset': 'rsc2015', 'use_dropout': True, 'reload_model': None, 'test_size': -1}\n",
      "Loading data\n",
      "Building model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock /home/sietze/.theano/compiledir_Linux-4.15--generic-x86_64-with-debian-buster-sid-x86_64-3.7.0-64/lock_dir/lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization\n",
      "101436 train examples\n",
      "11271 valid examples\n",
      "101849 test examples\n",
      "Epoch  0 Update  100 Loss  6.33902526142972\n",
      "Best perfomance updated!\n",
      "Valid Recall@20: 0.8431372549019608    Valid Mrr@20: 0.29636131314421615 \n",
      "Test Recall@20 0.8546279295820283    Test Mrr@20: 0.317541068572835\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 442.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Best performance=================\n",
      "Valid Recall@20: 0.8431372549019608    Valid Mrr@20: 0.29636131314421615 \n",
      "Test Recall@20 0.8546279295820283    Test Mrr@20: 0.317541068572835\n",
      "==================================================\n",
      "model options {'dim_proj': 40, 'hidden_units': 80, 'patience': 100, 'max_epochs': 1, 'dispFreq': 100, 'lrate': 0.002, 'n_items': 67172, 'encoder': 'gru', 'saveto': 'narm_model.npz', 'is_valid': True, 'is_save': False, 'batch_size': 512, 'valid_batch_size': 512, 'dataset': 'rsc2015', 'use_dropout': True, 'reload_model': None, 'test_size': -1}\n",
      "Loading data\n",
      "Building model\n",
      "Optimization\n",
      "101436 train examples\n",
      "11271 valid examples\n",
      "101849 test examples\n",
      "Epoch  0 Update  100 Loss  5.204226946192684\n",
      "Best perfomance updated!\n",
      "Valid Recall@20: 0.8649631798420726    Valid Mrr@20: 0.5177946403192198 \n",
      "Test Recall@20 0.8790267945684297    Test Mrr@20: 0.5448227244807731\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 442.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Best performance=================\n",
      "Valid Recall@20: 0.8649631798420726    Valid Mrr@20: 0.5177946403192198 \n",
      "Test Recall@20 0.8790267945684297    Test Mrr@20: 0.5448227244807731\n",
      "==================================================\n",
      "model options {'dim_proj': 40, 'hidden_units': 80, 'patience': 100, 'max_epochs': 1, 'dispFreq': 100, 'lrate': 0.003, 'n_items': 67172, 'encoder': 'gru', 'saveto': 'narm_model.npz', 'is_valid': True, 'is_save': False, 'batch_size': 512, 'valid_batch_size': 512, 'dataset': 'rsc2015', 'use_dropout': True, 'reload_model': None, 'test_size': -1}\n",
      "Loading data\n",
      "Building model\n",
      "Optimization\n",
      "101436 train examples\n",
      "11271 valid examples\n",
      "101849 test examples\n",
      "Epoch  0 Update  100 Loss  4.660415403994305\n",
      "Best perfomance updated!\n",
      "Valid Recall@20: 0.9035578032117825    Valid Mrr@20: 0.5922665797454736 \n",
      "Test Recall@20 0.9125862796885585    Test Mrr@20: 0.6131315708835294\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 434.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Best performance=================\n",
      "Valid Recall@20: 0.9035578032117825    Valid Mrr@20: 0.5922665797454736 \n",
      "Test Recall@20 0.9125862796885585    Test Mrr@20: 0.6131315708835294\n",
      "==================================================\n",
      "model options {'dim_proj': 40, 'hidden_units': 80, 'patience': 100, 'max_epochs': 1, 'dispFreq': 100, 'lrate': 0.004, 'n_items': 67172, 'encoder': 'gru', 'saveto': 'narm_model.npz', 'is_valid': True, 'is_save': False, 'batch_size': 512, 'valid_batch_size': 512, 'dataset': 'rsc2015', 'use_dropout': True, 'reload_model': None, 'test_size': -1}\n",
      "Loading data\n",
      "Building model\n",
      "Optimization\n",
      "101436 train examples\n",
      "11271 valid examples\n",
      "101849 test examples\n",
      "Epoch  0 Update  100 Loss  4.320554585518765\n",
      "Best perfomance updated!\n",
      "Valid Recall@20: 0.9073729039126963    Valid Mrr@20: 0.6668605823185181 \n",
      "Test Recall@20 0.9173973234886941    Test Mrr@20: 0.6903361008934936\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 442.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Best performance=================\n",
      "Valid Recall@20: 0.9073729039126963    Valid Mrr@20: 0.6668605823185181 \n",
      "Test Recall@20 0.9173973234886941    Test Mrr@20: 0.6903361008934936\n",
      "==================================================\n",
      "model options {'dim_proj': 50, 'hidden_units': 100, 'patience': 100, 'max_epochs': 1, 'dispFreq': 100, 'lrate': 0.001, 'n_items': 67172, 'encoder': 'gru', 'saveto': 'narm_model.npz', 'is_valid': True, 'is_save': False, 'batch_size': 512, 'valid_batch_size': 512, 'dataset': 'rsc2015', 'use_dropout': True, 'reload_model': None, 'test_size': -1}\n",
      "Loading data\n",
      "Building model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock /home/sietze/.theano/compiledir_Linux-4.15--generic-x86_64-with-debian-buster-sid-x86_64-3.7.0-64/lock_dir/lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization\n",
      "101436 train examples\n",
      "11271 valid examples\n",
      "101849 test examples\n",
      "Epoch  0 Update  100 Loss  6.065315064595074\n",
      "Best perfomance updated!\n",
      "Valid Recall@20: 0.8382574749356756    Valid Mrr@20: 0.44316845660016424 \n",
      "Test Recall@20 0.8568076269771917    Test Mrr@20: 0.46688773986927035\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 472.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Best performance=================\n",
      "Valid Recall@20: 0.8382574749356756    Valid Mrr@20: 0.44316845660016424 \n",
      "Test Recall@20 0.8568076269771917    Test Mrr@20: 0.46688773986927035\n",
      "==================================================\n",
      "model options {'dim_proj': 50, 'hidden_units': 100, 'patience': 100, 'max_epochs': 1, 'dispFreq': 100, 'lrate': 0.002, 'n_items': 67172, 'encoder': 'gru', 'saveto': 'narm_model.npz', 'is_valid': True, 'is_save': False, 'batch_size': 512, 'valid_batch_size': 512, 'dataset': 'rsc2015', 'use_dropout': True, 'reload_model': None, 'test_size': -1}\n",
      "Loading data\n",
      "Building model\n",
      "Optimization\n",
      "101436 train examples\n",
      "11271 valid examples\n",
      "101849 test examples\n",
      "Epoch  0 Update  100 Loss  5.064693825136162\n",
      "Best perfomance updated!\n",
      "Valid Recall@20: 0.8859905953331559    Valid Mrr@20: 0.5533061530517465 \n",
      "Test Recall@20 0.8977800469322232    Test Mrr@20: 0.5769769806230828\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 469.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Best performance=================\n",
      "Valid Recall@20: 0.8859905953331559    Valid Mrr@20: 0.5533061530517465 \n",
      "Test Recall@20 0.8977800469322232    Test Mrr@20: 0.5769769806230828\n",
      "==================================================\n",
      "model options {'dim_proj': 50, 'hidden_units': 100, 'patience': 100, 'max_epochs': 1, 'dispFreq': 100, 'lrate': 0.003, 'n_items': 67172, 'encoder': 'gru', 'saveto': 'narm_model.npz', 'is_valid': True, 'is_save': False, 'batch_size': 512, 'valid_batch_size': 512, 'dataset': 'rsc2015', 'use_dropout': True, 'reload_model': None, 'test_size': -1}\n",
      "Loading data\n",
      "Building model\n",
      "Optimization\n",
      "101436 train examples\n",
      "11271 valid examples\n",
      "101849 test examples\n",
      "Epoch  0 Update  100 Loss  4.397752366104653\n",
      "Best perfomance updated!\n",
      "Valid Recall@20: 0.9110105580693816    Valid Mrr@20: 0.6429706302006697 \n",
      "Test Recall@20 0.9181828000274916    Test Mrr@20: 0.6666781523659057\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 469.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Best performance=================\n",
      "Valid Recall@20: 0.9110105580693816    Valid Mrr@20: 0.6429706302006697 \n",
      "Test Recall@20 0.9181828000274916    Test Mrr@20: 0.6666781523659057\n",
      "==================================================\n",
      "model options {'dim_proj': 50, 'hidden_units': 100, 'patience': 100, 'max_epochs': 1, 'dispFreq': 100, 'lrate': 0.004, 'n_items': 67172, 'encoder': 'gru', 'saveto': 'narm_model.npz', 'is_valid': True, 'is_save': False, 'batch_size': 512, 'valid_batch_size': 512, 'dataset': 'rsc2015', 'use_dropout': True, 'reload_model': None, 'test_size': -1}\n",
      "Loading data\n",
      "Building model\n",
      "Optimization\n",
      "101436 train examples\n",
      "11271 valid examples\n",
      "101849 test examples\n",
      "Epoch  0 Update  100 Loss  4.108811932573534\n",
      "Best perfomance updated!\n",
      "Valid Recall@20: 0.9264484074172655    Valid Mrr@20: 0.6752767545456179 \n",
      "Test Recall@20 0.9289536470657542    Test Mrr@20: 0.6942919718119104\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 467.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Best performance=================\n",
      "Valid Recall@20: 0.9264484074172655    Valid Mrr@20: 0.6752767545456179 \n",
      "Test Recall@20 0.9289536470657542    Test Mrr@20: 0.6942919718119104\n",
      "==================================================\n",
      "model options {'dim_proj': 60, 'hidden_units': 120, 'patience': 100, 'max_epochs': 1, 'dispFreq': 100, 'lrate': 0.001, 'n_items': 67172, 'encoder': 'gru', 'saveto': 'narm_model.npz', 'is_valid': True, 'is_save': False, 'batch_size': 512, 'valid_batch_size': 512, 'dataset': 'rsc2015', 'use_dropout': True, 'reload_model': None, 'test_size': -1}\n",
      "Loading data\n",
      "Building model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock /home/sietze/.theano/compiledir_Linux-4.15--generic-x86_64-with-debian-buster-sid-x86_64-3.7.0-64/lock_dir/lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization\n",
      "101436 train examples\n",
      "11271 valid examples\n",
      "101849 test examples\n",
      "Epoch  0 Update  100 Loss  5.881110345955649\n",
      "Best perfomance updated!\n",
      "Valid Recall@20: 0.8561795759027593    Valid Mrr@20: 0.40215700837917073 \n",
      "Test Recall@20 0.8668519082170665    Test Mrr@20: 0.4162397329721049\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 505.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Best performance=================\n",
      "Valid Recall@20: 0.8561795759027593    Valid Mrr@20: 0.40215700837917073 \n",
      "Test Recall@20 0.8668519082170665    Test Mrr@20: 0.4162397329721049\n",
      "==================================================\n",
      "model options {'dim_proj': 60, 'hidden_units': 120, 'patience': 100, 'max_epochs': 1, 'dispFreq': 100, 'lrate': 0.002, 'n_items': 67172, 'encoder': 'gru', 'saveto': 'narm_model.npz', 'is_valid': True, 'is_save': False, 'batch_size': 512, 'valid_batch_size': 512, 'dataset': 'rsc2015', 'use_dropout': True, 'reload_model': None, 'test_size': -1}\n",
      "Loading data\n",
      "Building model\n",
      "Optimization\n",
      "101436 train examples\n",
      "11271 valid examples\n",
      "101849 test examples\n",
      "Epoch  0 Update  100 Loss  4.793136317595246\n",
      "Best perfomance updated!\n",
      "Valid Recall@20: 0.9074616271848106    Valid Mrr@20: 0.565727121400978 \n",
      "Test Recall@20 0.9143437834441183    Test Mrr@20: 0.5826348507533523\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 510.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Best performance=================\n",
      "Valid Recall@20: 0.9074616271848106    Valid Mrr@20: 0.565727121400978 \n",
      "Test Recall@20 0.9143437834441183    Test Mrr@20: 0.5826348507533523\n",
      "==================================================\n",
      "model options {'dim_proj': 60, 'hidden_units': 120, 'patience': 100, 'max_epochs': 1, 'dispFreq': 100, 'lrate': 0.003, 'n_items': 67172, 'encoder': 'gru', 'saveto': 'narm_model.npz', 'is_valid': True, 'is_save': False, 'batch_size': 512, 'valid_batch_size': 512, 'dataset': 'rsc2015', 'use_dropout': True, 'reload_model': None, 'test_size': -1}\n",
      "Loading data\n",
      "Building model\n",
      "Optimization\n",
      "101436 train examples\n",
      "11271 valid examples\n",
      "101849 test examples\n",
      "Epoch  0 Update  100 Loss  4.287125480577496\n",
      "Best perfomance updated!\n",
      "Valid Recall@20: 0.916600124212581    Valid Mrr@20: 0.6897883126835624 \n",
      "Test Recall@20 0.9241720586358236    Test Mrr@20: 0.7112752317159501\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 509.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Best performance=================\n",
      "Valid Recall@20: 0.916600124212581    Valid Mrr@20: 0.6897883126835624 \n",
      "Test Recall@20 0.9241720586358236    Test Mrr@20: 0.7112752317159501\n",
      "==================================================\n",
      "model options {'dim_proj': 60, 'hidden_units': 120, 'patience': 100, 'max_epochs': 1, 'dispFreq': 100, 'lrate': 0.004, 'n_items': 67172, 'encoder': 'gru', 'saveto': 'narm_model.npz', 'is_valid': True, 'is_save': False, 'batch_size': 512, 'valid_batch_size': 512, 'dataset': 'rsc2015', 'use_dropout': True, 'reload_model': None, 'test_size': -1}\n",
      "Loading data\n",
      "Building model\n",
      "Optimization\n",
      "101436 train examples\n",
      "11271 valid examples\n",
      "101849 test examples\n",
      "Epoch  0 Update  100 Loss  3.922542044396758\n",
      "Best perfomance updated!\n",
      "Valid Recall@20: 0.9181084198385236    Valid Mrr@20: 0.6717328041372179 \n",
      "Test Recall@20 0.9267444943003859    Test Mrr@20: 0.695090738082771\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 506.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Best performance=================\n",
      "Valid Recall@20: 0.9181084198385236    Valid Mrr@20: 0.6717328041372179 \n",
      "Test Recall@20 0.9267444943003859    Test Mrr@20: 0.695090738082771\n",
      "==================================================\n",
      "model options {'dim_proj': 50, 'hidden_units': 120, 'patience': 100, 'max_epochs': 10, 'dispFreq': 100, 'lrate': 0.004, 'n_items': 67172, 'encoder': 'gru', 'saveto': 'narm_model.npz', 'is_valid': True, 'is_save': True, 'batch_size': 512, 'valid_batch_size': 512, 'dataset': 'rsc2015', 'use_dropout': True, 'reload_model': None, 'test_size': -1}\n",
      "Loading data\n",
      "Building model\n",
      "Optimization\n",
      "101436 train examples\n",
      "11271 valid examples\n",
      "101849 test examples\n",
      "Epoch  0 Update  100 Loss  3.9340501427066736\n",
      "Saving...\n",
      "Saving done\n",
      "Best perfomance updated!\n",
      "Valid Recall@20: 0.904711205749268    Valid Mrr@20: 0.5932955307928526 \n",
      "Test Recall@20 0.916111105656413    Test Mrr@20: 0.6217663952735066\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 504.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 Update  200 Loss  1.759842010769674\n",
      "Epoch  1 Update  300 Loss  1.5257248014014553\n",
      "Saving...\n",
      "Saving done\n",
      "Best perfomance updated!\n",
      "Valid Recall@20: 0.9329252062816077    Valid Mrr@20: 0.7881395965355543 \n",
      "Test Recall@20 0.9393808481182928    Test Mrr@20: 0.8083240421390502\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 510.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 Update  400 Loss  1.256207239735788\n",
      "Epoch  2 Update  500 Loss  1.1706680303309793\n",
      "Saving...\n",
      "Saving done\n",
      "Valid Recall@20: 0.9315943571998936    Valid Mrr@20: 0.8233949964802014 \n",
      "Test Recall@20 0.9393513927480879    Test Mrr@20: 0.8391687338951187\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 502.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 Update  600 Loss  1.1059156172737892\n",
      "Epoch  3 Update  700 Loss  1.049296732240904\n",
      "Saving...\n",
      "Saving done\n",
      "Best perfomance updated!\n",
      "Valid Recall@20: 0.9366515837104072    Valid Mrr@20: 0.8254117571645597 \n",
      "Test Recall@20 0.9433867784661607    Test Mrr@20: 0.8413880222943411\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 505.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 Update  800 Loss  0.9738303728447849\n",
      "Epoch  4 Update  900 Loss  1.009934612092863\n",
      "Saving...\n",
      "Saving done\n",
      "Best perfomance updated!\n",
      "Valid Recall@20: 0.9417975334930352    Valid Mrr@20: 0.8267518732754624 \n",
      "Test Recall@20 0.9471276104821844    Test Mrr@20: 0.842106364860305\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 506.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 Update  1000 Loss  0.9810501059260306\n",
      "Epoch  5 Update  1100 Loss  0.9913024746743462\n",
      "Saving...\n",
      "Saving done\n",
      "Valid Recall@20: 0.9409103007718924    Valid Mrr@20: 0.8178872307297905 \n",
      "Test Recall@20 0.9471668843091243    Test Mrr@20: 0.8337047285425787\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 505.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 Update  1200 Loss  1.0015472837151378\n",
      "Epoch  6 Update  1300 Loss  0.9784964393607578\n",
      "Saving...\n",
      "Saving done\n",
      "Valid Recall@20: 0.9385147724248071    Valid Mrr@20: 0.8208740974698803 \n",
      "Test Recall@20 0.9447711808657915    Test Mrr@20: 0.8374316740664245\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 507.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 Update  1400 Loss  0.9746375096317096\n",
      "Epoch  7 Update  1500 Loss  0.964134390258779\n",
      "Saving...\n",
      "Saving done\n",
      "Valid Recall@20: 0.9403779611392068    Valid Mrr@20: 0.822723524159368 \n",
      "Test Recall@20 0.9446533593849719    Test Mrr@20: 0.8406432242056049\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 504.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 Update  1600 Loss  0.9655943790128871\n",
      "Epoch  8 Update  1700 Loss  0.964616491385202\n",
      "Saving...\n",
      "Saving done\n",
      "Valid Recall@20: 0.9390471120574927    Valid Mrr@20: 0.8213549597527267 \n",
      "Test Recall@20 0.9438875197596441    Test Mrr@20: 0.8378535795737015\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 501.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 Update  1800 Loss  0.9264114008613722\n",
      "Epoch  9 Update  1900 Loss  0.9566487137688621\n",
      "Saving...\n",
      "Saving done\n",
      "Valid Recall@20: 0.941087747316121    Valid Mrr@20: 0.8265488464272713 \n",
      "Test Recall@20 0.947618533318933    Test Mrr@20: 0.8420211106458694\n",
      "Seen 101436 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This epoch took 504.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Best performance=================\n",
      "Valid Recall@20: 0.9417975334930352    Valid Mrr@20: 0.8267518732754624 \n",
      "Test Recall@20 0.9471276104821844    Test Mrr@20: 0.842106364860305\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50, 0.004)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch = False\n",
    "if gridsearch:\n",
    "    gridsearch()\n",
    "else\n",
    "    dim_proj= 50\n",
    "    lrate = 0.004\n",
    "    eval_valid, eval_test = train_gru(dim_proj=best_dim_proj,\n",
    "                                      hidden_units=dim_proj*2, \n",
    "                                      max_epochs=10, \n",
    "                                      lrate = best_lrate, \n",
    "                                      n_items=n_itemsL, \n",
    "                                      is_save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
